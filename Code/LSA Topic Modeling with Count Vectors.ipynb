{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I use lsa with count vectors to create 3 topics. I also looked at the explained variance for each topic and tried to distinguish what each topic was clustered around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.feature_extraction import text \n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reads in a csv, drops Unnamed column, tokenizes, removes reviews that are 10 words or less and creates\n",
    "#modelling text column with the tokens.\n",
    "df = pd.read_csv('tokenized_text')\n",
    "\n",
    "df.drop(columns = 'Unnamed: 0', inplace = True)\n",
    "\n",
    "df['tokens'] = df['text'].apply(simple_preprocess)\n",
    "\n",
    "df = df[(df.tokens.str.len() > 10)]\n",
    "\n",
    "df['modeling_text'] = df['tokens'].apply(lambda x:' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cast the modeling_text to a variable\n",
    "example = df['modeling_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes a df of word counts and threshold for number of times a word appears and returns a dataframe with\n",
    "#containing the number of times each word appears. This is useful for adding custom stop words.\n",
    "def common_words(df_word_count, n):\n",
    "    df_word_count = df_word_count.T.reset_index()\n",
    "    df_word_count['Word Total']= df_word_count.iloc[1:,-3558:-1].sum(axis=1)\n",
    "    common_words = df_word_count[df_word_count['Word Total'] > n]\n",
    "    return common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding custom stop words\n",
    "stopword = set(stopwords.words('english'))\n",
    "\n",
    "stopword = stopword.union(set(['food', 'this', 'place', 'the', 'of', 'is', 'came', 'was', 'for', 'have', 'had'\n",
    "                           ,'and', 'get', 'one', 'food', 'guy','?','!','place', 'good', 'fries','burger', 'burgers',\n",
    "                            'got', 'eat','great', 'us', 'asked', 'service', 'back', 'time', 'like', 'vegas', 'go',\n",
    "                            'try', 'animal', 'style', 'double', 'good', 'just', 'always', 'location', 'fresh',\n",
    "                              'east', 'coast', 'order', 'ordered', 'fast']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converts the modeling text to a count of the words using CountVectorizer\n",
    "vectorizer = CountVectorizer(min_df = 1, stop_words = stopword)\n",
    "dtm = vectorizer.fit_transform(example)  # dtm: Document-Term Matrix\n",
    "df_word_count = pd.DataFrame(dtm.toarray(), index=example, columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit LSA. Use algorithm = “randomized” for large datasets \n",
    "num_topics = 20\n",
    "lsa = TruncatedSVD(num_topics, algorithm = 'randomized')\n",
    "dtm_lsa = lsa.fit_transform(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting number of topics against explained variance\n",
    "plt.figure(figsize=[15,5])\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(lsa.explained_variance_ratio_)\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Explained Variance Ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting most common words for topic 1\n",
    "pd.DataFrame(lsa.components_.round(5),index = [\"1\",'2', '3'],columns = vectorizer.get_feature_names()).T.sort_values(by='1', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Extracting most common words for topic 2\n",
    "pd.DataFrame(lsa.components_.round(5),index = [\"1\",'2', '3'],columns = vectorizer.get_feature_names()).T.sort_values(by='2', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting most common words for topic 3\n",
    "pd.DataFrame(lsa.components_.round(5),index = [\"1\",'2', '3'],columns = vectorizer.get_feature_names()).T.sort_values(by='3', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the topic probablilites of each review to a CSV\n",
    "topic_probs = pd.DataFrame(dtm_lsa.round(5), index = example, columns = ['1','2', '3'])\n",
    "\n",
    "topic_probs.reset_index().to_csv('lsi_topic_probs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This section was trying to extract reviews that had the highest probabilities to be in each topic.\n",
    "#I wanted to look at them to see if there was an obvious difference between the 3.\n",
    "text_1 = []\n",
    "text_2 = []\n",
    "text_3 = []\n",
    "for i in range(len(topic_probs)):\n",
    "    if topic_probs.iloc[i]['1'] > 8:\n",
    "        text_1.append(topic_probs.iloc[i]['modeling_text'])\n",
    "    elif topic_probs.iloc[i]['2'] > 5:\n",
    "        text_2.append(topic_probs.iloc[i]['modeling_text'])\n",
    "    if topic_probs.iloc[i]['3'] > 2:\n",
    "        text_3.append(topic_probs.iloc[i]['modeling_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"text_1\",\"w\",newline=\"\") as f:  # open(\"output.csv\",\"wb\") for Python 2\n",
    "    cw = csv.writer(f)\n",
    "    cw.writerows(r for r in text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at cosine_similarity of the reviews to see if they are related in an obvious way.\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "pd.DataFrame(cosine_similarity(dtm_lsa,dtm_lsa).round(6), columns =example, index = example)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
